{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Train_ETRI_BERT.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1db247c49f95441db1b3e594c478756e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4abbdb48d5d24d1d8a0dae536c0bc99d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4ae90ec2ca7472c91c7e73a3cc6abb6","IPY_MODEL_ea3c78d916554338bd2c8256dbf259ff"]}},"4abbdb48d5d24d1d8a0dae536c0bc99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4ae90ec2ca7472c91c7e73a3cc6abb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d895da7a68094a97a60ab7a0794b552a","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aced469e66114b598fd0b1c37e8d2afa"}},"ea3c78d916554338bd2c8256dbf259ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f625899dd93446f950d0d51776098df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5938/5938 [3:15:21&lt;00:00,  1.97s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c5ee7921ae3f46a19bbadb56d6d8cc1e"}},"d895da7a68094a97a60ab7a0794b552a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aced469e66114b598fd0b1c37e8d2afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f625899dd93446f950d0d51776098df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c5ee7921ae3f46a19bbadb56d6d8cc1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38fd78e4400a4d19866b6eeedd483472":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_27cfb43a3a0146d89c70099753f77cd4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0063cc413eb044c39837e7956e29e0a5","IPY_MODEL_834ffdbc9d7d4379b06388856f9c48fc"]}},"27cfb43a3a0146d89c70099753f77cd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0063cc413eb044c39837e7956e29e0a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8e2c6e5348714ba094b7d81dbb8a2898","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6822b644ad434cb08ed47599f4d2a623"}},"834ffdbc9d7d4379b06388856f9c48fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a54cbad126b489ba3d4ed3300f5b15d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1485/1485 [2:39:02&lt;00:00,  6.43s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_999b3fc97f2f4141b044584d75e08f91"}},"8e2c6e5348714ba094b7d81dbb8a2898":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6822b644ad434cb08ed47599f4d2a623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a54cbad126b489ba3d4ed3300f5b15d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"999b3fc97f2f4141b044584d75e08f91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afca0de462244a078ec0f417d1e074e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ec93ba8c16747fb9b1334f8456db039","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c7a368dff88b415dad6659e34edb9cb3","IPY_MODEL_afc5ee3957764053b141758432344465"]}},"6ec93ba8c16747fb9b1334f8456db039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7a368dff88b415dad6659e34edb9cb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8462ce9fd0494348afadeab3d0d60eef","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_564ce17861ba4ba0a12cbf8e1a706b8b"}},"afc5ee3957764053b141758432344465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_99cde03760bf4713b302afefd0461cb7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5938/5938 [38:58&lt;00:00,  2.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba4f44e05c564376bdc23280693f4f29"}},"8462ce9fd0494348afadeab3d0d60eef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"564ce17861ba4ba0a12cbf8e1a706b8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99cde03760bf4713b302afefd0461cb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba4f44e05c564376bdc23280693f4f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1a56753b4914d1680ffbcab279fcaec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_09c2d8b8530c431680735bdd16597f3b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_284d707154da4a0f9d5efe5a9d5c238f","IPY_MODEL_1b32eda0b9304451aa03c07fbcf3c2a8"]}},"09c2d8b8530c431680735bdd16597f3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"284d707154da4a0f9d5efe5a9d5c238f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_262f439c30624afe8b27ef153021a4c4","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa4e75cbb25f4a36b9082cc73fd78bfa"}},"1b32eda0b9304451aa03c07fbcf3c2a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e738a153e7b240b4b0e1f706b11c5136","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1485/1485 [03:13&lt;00:00,  7.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58b4492f8d2844d4bd9bd87a2e00bf22"}},"262f439c30624afe8b27ef153021a4c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa4e75cbb25f4a36b9082cc73fd78bfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e738a153e7b240b4b0e1f706b11c5136":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"58b4492f8d2844d4bd9bd87a2e00bf22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9afc37719004dd3977808227ac67796":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3a56b362b2914a7fa71bc8af06286bff","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_36e03f0011c447bbb17c8672867b3181","IPY_MODEL_8cf855fe8d3d4160974d8fc78b30ceaf"]}},"3a56b362b2914a7fa71bc8af06286bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36e03f0011c447bbb17c8672867b3181":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_549e981b42d84d908107394dc79ba46c","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a2b4616f2814c11b330a4495c74c765"}},"8cf855fe8d3d4160974d8fc78b30ceaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c5c845f804014a0c96ceacf150d61578","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5938/5938 [1:56:50&lt;00:00,  1.18s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d8d8f51231f448fbe751ac5599a5cfa"}},"549e981b42d84d908107394dc79ba46c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2a2b4616f2814c11b330a4495c74c765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5c845f804014a0c96ceacf150d61578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d8d8f51231f448fbe751ac5599a5cfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9b6d4bcc3ab485082684f0177ea52e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8df59fb361bd4b35b8fcecd2583c8956","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_66b4a3da6fe4457898d8d1afaf28c636","IPY_MODEL_2f466af5e283483799718b33ace55c9f"]}},"8df59fb361bd4b35b8fcecd2583c8956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66b4a3da6fe4457898d8d1afaf28c636":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_760c5513feb6405695e613de585cb766","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a47f971d68f4b5bb175f3619c49d0bc"}},"2f466af5e283483799718b33ace55c9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6401284de6ba482b8e54accc6cca86ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1485/1485 [42:09&lt;00:00,  1.70s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52ccae12d1f046ada3da452fd15055c6"}},"760c5513feb6405695e613de585cb766":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a47f971d68f4b5bb175f3619c49d0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6401284de6ba482b8e54accc6cca86ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"52ccae12d1f046ada3da452fd15055c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"418623166f9f42869dc6af770dce1466":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4d23bcea341430894639f6a22cee552","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a1eac4b6dc4943b39baa551081199673","IPY_MODEL_6fe8e974554c436e804f18ee46960264"]}},"a4d23bcea341430894639f6a22cee552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1eac4b6dc4943b39baa551081199673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7f8373c8133b4749a1bea6bcf8d44a98","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7052ff4bd3a4fbabe442a2db576a181"}},"6fe8e974554c436e804f18ee46960264":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d119cef17ab54b059b1947fb69d159da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5938/5938 [38:55&lt;00:00,  2.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90ce211d129b4588afdfc98277f4dbab"}},"7f8373c8133b4749a1bea6bcf8d44a98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a7052ff4bd3a4fbabe442a2db576a181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d119cef17ab54b059b1947fb69d159da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90ce211d129b4588afdfc98277f4dbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3057181306764341bd509ca7a0f2ade9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b008aff685f348f2b9ec696374781710","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d609d75f19a648e98a7b54dde840fd68","IPY_MODEL_5b9c1cb15cb9473c9caff03810f631fb"]}},"b008aff685f348f2b9ec696374781710":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d609d75f19a648e98a7b54dde840fd68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d255260ce4b845f08c3ad6648bbcec91","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f67a737653fa4559b7541a0e8c6b8a9f"}},"5b9c1cb15cb9473c9caff03810f631fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0e7ce60e97164f13b53646d3fad669bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1485/1485 [03:13&lt;00:00,  7.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7b388bc0c8245f1a01250399b60c375"}},"d255260ce4b845f08c3ad6648bbcec91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f67a737653fa4559b7541a0e8c6b8a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e7ce60e97164f13b53646d3fad669bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7b388bc0c8245f1a01250399b60c375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46b8183833fd499db3d2555163a26300":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8de4ea31ff5e4c518777b9d70436ccdb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_757dae685c8844aea78bacaf0fa3c5d7","IPY_MODEL_f4ed546053404a5f9058657664fde2fc"]}},"8de4ea31ff5e4c518777b9d70436ccdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"757dae685c8844aea78bacaf0fa3c5d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7647feb5eaa04c15ba3dacfa0ac2fb54","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a19a8c8de46e492099c95d1c05b0de40"}},"f4ed546053404a5f9058657664fde2fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_01c37a421eb741198191316aeecd7a03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5938/5938 [38:56&lt;00:00,  2.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f4190ec47ed451b97c18bf29bb9dfe5"}},"7647feb5eaa04c15ba3dacfa0ac2fb54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a19a8c8de46e492099c95d1c05b0de40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01c37a421eb741198191316aeecd7a03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f4190ec47ed451b97c18bf29bb9dfe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2aa1e66fb535426b9d3ce693212e6f3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a4c1895649849409dc94e589cf9b5b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06204f18ce1845cba6b109d8595ffed6","IPY_MODEL_701a90c5a4e1425cad9fb6cfe47058ba"]}},"4a4c1895649849409dc94e589cf9b5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06204f18ce1845cba6b109d8595ffed6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_192a1deb8934418b970bc84eaed02bfe","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1485,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1485,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ee544d1e82e4574b1b433cd898cba3e"}},"701a90c5a4e1425cad9fb6cfe47058ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_59653ff68e874aa09504a85114669bdc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1485/1485 [03:13&lt;00:00,  7.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5af0c413ddc42f1b8d029bf6733a828"}},"192a1deb8934418b970bc84eaed02bfe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9ee544d1e82e4574b1b433cd898cba3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59653ff68e874aa09504a85114669bdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a5af0c413ddc42f1b8d029bf6733a828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef853bae0b4b4818b3e1b0aa82b5c878":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5c0f77beb4104b36adeec6d73b526b0c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_906762c963144135bc0a175344bc83a4","IPY_MODEL_4b6fb492287f44bba756c9f8d08f7350"]}},"5c0f77beb4104b36adeec6d73b526b0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"906762c963144135bc0a175344bc83a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce43ebfb28b14c48b090f73bc9859b39","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":142565,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":142565,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26f2e1353f864427a19093ac986bfed9"}},"4b6fb492287f44bba756c9f8d08f7350":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5dc2fbe45a8b4025a373c75c7538f516","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 142565/142565 [00:32&lt;00:00, 4380.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f54b600063f946379ff0caacac85e9a8"}},"ce43ebfb28b14c48b090f73bc9859b39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"26f2e1353f864427a19093ac986bfed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5dc2fbe45a8b4025a373c75c7538f516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f54b600063f946379ff0caacac85e9a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lY9ZuJ9LISQ","executionInfo":{"status":"ok","timestamp":1609476839575,"user_tz":-540,"elapsed":23973,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"cc63188e-5fb1-4277-b819-ec8445ec6fb3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pCnjFpzwB5Tj"},"source":["## 1. 패키지 설치 및 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"pjlFSKDF6l1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609476841003,"user_tz":-540,"elapsed":25390,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"e602f939-4243-4c8c-dda9-3731899e4fb0"},"source":["!pip install pytorch_pretrained_bert==0.4.0\r\n","!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\r\n","%cd Mecab-ko-for-Google-Colab\r\n","# 토크나이저 mecab 설치\r\n","! bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 75, done.\u001b[K\n","remote: Counting objects: 100% (75/75), done.\u001b[K\n","remote: Compressing objects: 100% (70/70), done.\u001b[K\n","remote: Total 75 (delta 33), reused 20 (delta 5), pack-reused 0\u001b[K\n","Unpacking objects: 100% (75/75), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXGLjyoJMmgQ","executionInfo":{"status":"ok","timestamp":1609476998808,"user_tz":-540,"elapsed":164508,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"7825a820-4fd1-47e8-99fe-dc99e79b0aed"},"source":["cd /content/drive/MyDrive/마이야르/6.Code "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1enR-TKNggkQ_bAdN7UF7isfRkeewUc_-/NH_dacon/태욱\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HmnbcXH2K9KF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609477003277,"user_tz":-540,"elapsed":167823,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"d526b940-0f81-4baf-da41-58bb62238a33"},"source":["from __future__ import absolute_import, division, print_function\n","\n","import argparse\n","import csv\n","import logging\n","import os\n","import random\n","import sys\n","import warnings\n","import pickle\n","warnings.filterwarnings(\"ignore\")\n","\n","from collections import Counter\n","import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange, tqdm_notebook, notebook\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n","### kyoungman.bae @ 19-05-28 \n","# from tokenization_morp import BertTokenizer\n","from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n","\n","import urllib3\n","import json\n","\n","from konlpy.tag import Mecab\n","# from khaiii import KhaiiiApi\n","# import kss\n","\n","mecab = Mecab()\n","# khaiii = KhaiiiApi()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"0uTDnksxNiGR","executionInfo":{"status":"ok","timestamp":1609477770644,"user_tz":-540,"elapsed":3578,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"6002ce78-30b3-46ca-c919-e4c6934657b7"},"source":["train_df = pd.read_csv(\"/content/drive/MyDrive/마이야르/1.Data/news_train.csv\")\r\n","test_df = pd.read_csv(\"/content/drive/MyDrive/마이야르/1.Data/news_test.csv\")\r\n","submission = pd.read_csv(\"/content/drive/MyDrive/마이야르/1.Data/sample_submission.csv\")\r\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>n_id</th>\n","      <th>date</th>\n","      <th>title</th>\n","      <th>content</th>\n","      <th>ord</th>\n","      <th>info</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NEWS02580</td>\n","      <td>20200605</td>\n","      <td>[마감]코스닥 기관 678억 순매도</td>\n","      <td>[이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NEWS02580</td>\n","      <td>20200605</td>\n","      <td>[마감]코스닥 기관 678억 순매도</td>\n","      <td>\"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NEWS02580</td>\n","      <td>20200605</td>\n","      <td>[마감]코스닥 기관 678억 순매도</td>\n","      <td>하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NEWS02580</td>\n","      <td>20200605</td>\n","      <td>[마감]코스닥 기관 678억 순매도</td>\n","      <td>종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NEWS09727</td>\n","      <td>20200626</td>\n","      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n","      <td>전국적인 소비 붐 조성에 기여할 예정</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        n_id      date  ... ord info\n","0  NEWS02580  20200605  ...   1    0\n","1  NEWS02580  20200605  ...   2    1\n","2  NEWS02580  20200605  ...   3    1\n","3  NEWS02580  20200605  ...   4    0\n","4  NEWS09727  20200626  ...   1    0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"aFHwAEoxIhqY"},"source":["## 2. 전처리 및 모델 세팅"]},{"cell_type":"code","metadata":{"id":"ExYE72ZBjOvt"},"source":["train, validation, train_labels, validation_labels = train_test_split(train_df.iloc[:,:-1], train_df['info'], \r\n","                                                                   random_state=2020, test_size=0.2)\r\n","\r\n","train = pd.concat([train,train_labels],axis=1)\r\n","validation = pd.concat([validation,validation_labels],axis=1)\r\n","\r\n","train.to_csv('/content/drive/MyDrive/마이야르/1.Data/train.csv', index=False)\r\n","validation.to_csv('/content/drive/MyDrive/마이야르/1.Data/dev.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueoHecDCMpx1"},"source":["def construct_vocab(file_, max_size=200000, mincount=5):\r\n","    vocab2id = {'[CLS]': 2, '[SEP]': 3, '[PAD]': 0, '[UNK]': 1, '[STOP]': 4}\r\n","    # id2vocab = {2: '[CLS]', 3: '[SEP]', 0: '[PAD]', 1: '[UNK]', 4: '[STOP]'}\r\n","    word_pad = {'[CLS]': 2, '[SEP]': 3, '[PAD]': 0, '[UNK]': 1, '[STOP]': 4}\r\n","    \r\n","    cnt = len(vocab2id)\r\n","    with open(file_, 'r') as fp:\r\n","      for line in fp:\r\n","        arr = re.split('\\t', line[:-1])\r\n","        if (arr[0] in [' ', 'n_iters=10000', 'max_length=16', '[MASK]','<S>','<T>']) :\r\n","          continue\r\n","        if arr[0] in word_pad:\r\n","          continue\r\n","        if int(arr[1]) >= mincount:\r\n","          vocab2id[arr[0]] = cnt\r\n","          cnt += 1\r\n","        if len(vocab2id) == max_size:\r\n","          break\r\n","  \r\n","    return vocab2id\r\n","\r\n","vocab2id = construct_vocab('/content/drive/MyDrive/마이야르/4.pre_trained embedding/korbert/vocab.korean_morp.list')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2-MHKqGmemB"},"source":["## abstract data\r\n","def mecab_tokenizer(x):\r\n","  \r\n","  #sntc_list = kss.split_sentences(x)\r\n","  tk = []\r\n","\r\n","  token = mecab.pos(x)\r\n","\r\n","  #print(token)\r\n","  for t in token:\r\n","    if t[1] == 'NNBC':\r\n","      #print(t[0] + \"/\" + t[1] + \"_\")\r\n","      tk += [t[0] + \"/\" + \"NNB\" + \"_\"]\r\n","    elif  (t[1] == 'SSO') or (t[1] == 'SSC'):\r\n","      #print(t[0] + \"/\" + t[1] + \"_\")\r\n","      tk += [t[0] + \"/\" + \"SS\" + \"_\"]\r\n","    elif t[1] == 'SY':\r\n","      #print(t[0] + \"/\" + t[1] + \"_\")\r\n","      tk += [t[0] + \"/\" + \"SW\" + \"_\"]\r\n","    else: \r\n","      #print(t[0] + \"/\" + t[1] + \"_\")\r\n","      tk += [t[0] + \"/\" + t[1] + \"_\"]\r\n","\r\n","  return tk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8r7opwOccqZb"},"source":["logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\r\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\r\n","                    level = logging.INFO)\r\n","logger = logging.getLogger(__name__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oR5a-g7Cf3i5"},"source":["import easydict \r\n","args = easydict.EasyDict({\"data_dir\": '/content/drive/MyDrive/마이야르/1.Data',\r\n","                          \"task_name\":'cola',\r\n","                          \"output_dir\":'/content/drive/MyDrive/마이야르/5.Model/bert_tu',\r\n","                          \"vocab_file\":'/content/drive/MyDrive/마이야르/4.pre_trained embedding/korbert/vocab.korean_morp.list',\r\n","                          \"openapi_key\":'',\r\n","                          \"bert_model_path\":'/content/drive/MyDrive/마이야르/4.pre_trained embedding/korbert',\r\n","                          \"cache_dir\":'',\r\n","                          \"max_seq_length\":200,\r\n","                          \"do_train\":True,\r\n","                          \"do_eval\":False,\r\n","                          \"do_lower_case\":False,\r\n","                          \"train_batch_size\":16,\r\n","                          \"eval_batch_size\":16,\r\n","                          \"learning_rate\":2e-5,\r\n","                          \"num_train_epochs\":5,\r\n","                          \"warmup_proportion\":0.1,\r\n","                          \"no_cuda\": False,\r\n","                          \"local_rank\":-1,\r\n","                          \"seed\":42,\r\n","                          \"gradient_accumulation_steps\":1,\r\n","                          \"fp16\":False,\r\n","                          \"loss_scale\":0,\r\n","                          \"server_ip\":'',\r\n","                          \"server_port\":''    \r\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdB7U_GcdZGs"},"source":["class InputExample(object):\r\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\r\n","\r\n","    def __init__(self, guid, text_a, text_b=None, label=None):\r\n","        \"\"\"Constructs a InputExample.\r\n","\r\n","        Args:\r\n","            guid: Unique id for the example.\r\n","            text_a: string. The untokenized text of the first sequence. For single\r\n","            sequence tasks, only this sequence must be specified.\r\n","            text_b: (Optional) string. The untokenized text of the second sequence.\r\n","            Only must be specified for sequence pair tasks.\r\n","            label: (Optional) string. The label of the example. This should be\r\n","            specified for train and dev examples, but not for test examples.\r\n","        \"\"\"\r\n","        self.guid = guid\r\n","        self.text_a = text_a\r\n","        self.text_b = text_b\r\n","        self.label = label\r\n","\r\n","\r\n","class InputFeatures(object):\r\n","    \"\"\"A single set of features of data.\"\"\"\r\n","    \r\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id, sentence_id=None):\r\n","        self.input_ids = input_ids\r\n","        self.input_mask = input_mask\r\n","        self.segment_ids = segment_ids\r\n","        self.label_id = label_id\r\n","\r\n","\r\n","class DataProcessor(object):\r\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\r\n","        raise NotImplementedError()\r\n","    \r\n","    def get_test_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_labels(self):\r\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","\r\n","    def _read_csv(self,input_file):\r\n","        return pd.read_csv(input_file)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XS-Us6DIu-w"},"source":["class ColaProcessor(DataProcessor):\r\n","    \"\"\"Processor for the CoLA data set (GLUE version).\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_csv(os.path.join(data_dir, \"train.csv\")), \"train\")\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_csv(os.path.join(data_dir, \"dev.csv\")), \"dev\")\r\n","  \r\n","    def get_test_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_csv(os.path.join(data_dir, \"news_test.csv\")), \"test\")\r\n","\r\n","    def get_labels(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        ######################################################################\r\n","        ### kyoungman.bae @ 19-05-30 @ for multi label classification\r\n","        ### You need to add a file with label information in the data folder. \r\n","        ### You should use a numbered label on a line.\r\n","        labels =[]\r\n","        lines = self._read_tsv(os.path.join(data_dir, \"labels.tsv\"))\r\n","        for (i, line) in enumerate(lines):\r\n","            labels.append(str(line[0]))   \r\n","        return labels\r\n","       # return [\"0\", \"1\"]\r\n","\r\n","    # def _create_examples(self, lines, set_type):\r\n","    #     \"\"\"Creates examples for the training and dev sets.\"\"\"\r\n","    #     examples = []\r\n","    #     for (i, line) in enumerate(lines):\r\n","    #         guid = \"%s-%s\" % (set_type, i)\r\n","    #         text_a = line[3]\r\n","    #         label = line[5]\r\n","    #         examples.append(\r\n","    #             InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\r\n","    #     return examples\r\n","    \r\n","    def _create_examples(self, lines, set_type):\r\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\r\n","        examples = []\r\n","        for i in range(len(lines)):\r\n","          guid = \"%s-%s\" % (set_type, i)\r\n","          text_a = lines.loc[i,'title']\r\n","          try:\r\n","            label = lines.loc[i,'info']\r\n","          except:\r\n","            label = 0\r\n","          text_b = lines.loc[i,'content']\r\n","          examples.append(\r\n","              InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\r\n","        return examples\r\n","\r\n","### kyoungman.bae @ 19-05-28 @ \r\n","def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, openapi_key):\r\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\r\n","\r\n","    label_map = {label : i for i, label in enumerate(label_list)}\r\n","    ### kyoungman.bae @ 19-05-28 @\r\n","    features = []\r\n","    for (ex_index, example) in enumerate(examples):\r\n","        tokens_a = \"\"\r\n","        tokens_b = \"\"\r\n","\r\n","        tokens_a = tokenizer(example.text_a)    \r\n","        tokens_b = tokenizer(example.text_b)\r\n","\r\n","        # tokens_b = None\r\n","        if example.text_b:\r\n","\r\n","        #     # Modifies `tokens_a` and `tokens_b` in place so that the total\r\n","        #     # length is less than the specified length.\r\n","        #     # Account for [CLS], [SEP], [SEP] with \"- 3\"\r\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\r\n","        else:\r\n","        #     # Account for [CLS] and [SEP] with \"- 2\"\r\n","            if len(tokens_a) > max_seq_length - 2:\r\n","                tokens_a = tokens_a[:(max_seq_length-2)]\r\n","\r\n","        # The convention in BERT is:\r\n","        # (a) For sequence pairs:\r\n","        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\r\n","        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\r\n","        # (b) For single sequences:\r\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\r\n","        #  type_ids: 0   0   0   0  0     0 0\r\n","        #\r\n","        # Where \"type_ids\" are used to indicate whether this is the first\r\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\r\n","        # `type=1` were learned during pre-training and are added to the wordpiece\r\n","        # embedding vector (and position vector). This is not *strictly* necessary\r\n","        # since the [SEP] token unambigiously separates the sequences, but it makes\r\n","        # it easier for the model to learn the concept of sequences.\r\n","        #\r\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\r\n","        # used as as the \"sentence vector\". Note that this only makes sense because\r\n","        # the entire model is fine-tuned.\r\n","        if len(tokens_a) > (max_seq_length - 2):\r\n","          tokens_a = tokens_a[:max_seq_length - 2]\r\n","\r\n","        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\r\n","        segment_ids = [0] * len(tokens)\r\n","\r\n","        if tokens_b:\r\n","            tokens += tokens_b + [\"[SEP]\"]\r\n","            segment_ids += [1] * (len(tokens_b) + 1)\r\n","\r\n","        input_ids = [vocab2id[i] if i in vocab2id else vocab2id['[UNK]'] for i in tokens] \r\n","\r\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n","        # tokens are attended to.\r\n","        input_mask = [1] * len(input_ids)\r\n","\r\n","        # Zero-pad up to the sequence length.\r\n","        padding = [0] * (max_seq_length - len(input_ids))\r\n","        input_ids += padding\r\n","        input_mask += padding\r\n","        segment_ids += padding\r\n"," \r\n","\r\n","     \r\n","        assert len(input_ids) == max_seq_length\r\n","        assert len(input_mask) == max_seq_length\r\n","        assert len(segment_ids) == max_seq_length\r\n","        #print(ex_index)        \r\n","        label_id = label_map[str(example.label)]\r\n","        \r\n","        if ex_index < 5:\r\n","            logger.info(\"*** Example ***\")\r\n","            logger.info(\"guid: %s\" % (example.guid))\r\n","            logger.info(\"tokens: %s\" % \" \".join(\r\n","                    [str(x) for x in tokens]))\r\n","            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\r\n","            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\r\n","            logger.info(\r\n","                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\r\n","            logger.info(\"label: %s (id = %d)\" % (str(example.label), label_id))\r\n","        senid = example.guid+\"\"\r\n","        features.append(\r\n","                InputFeatures(input_ids=input_ids,\r\n","                              input_mask=input_mask,\r\n","                              segment_ids=segment_ids,\r\n","                              label_id=label_id))\r\n","    return features\r\n","    \r\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\r\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\r\n","\r\n","    # This is a simple heuristic which will always truncate the longer sequence\r\n","    # one token at a time. This makes more sense than truncating an equal percent\r\n","    # of tokens from each, since if one sequence is very short then each token\r\n","    # that's truncated likely contains more information than a longer sequence.\r\n","    while True:\r\n","        total_length = len(tokens_a) + len(tokens_b)\r\n","        if total_length <= max_length:\r\n","            break\r\n","        if len(tokens_a) > len(tokens_b):\r\n","            tokens_a.pop()\r\n","        else:\r\n","            tokens_b.pop()\r\n","\r\n","def accuracy(out, labels):\r\n","    outputs = np.argmax(out, axis=1)\r\n","    return np.sum(outputs == labels)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44Fq0rBM7FzA"},"source":["processors = {\r\n","    \"cola\": ColaProcessor\r\n","}\r\n","\r\n","num_labels_task = {\r\n","    \"cola\": 2\r\n","}\r\n","\r\n","if args.local_rank == -1 or args.no_cuda:\r\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\r\n","    n_gpu = torch.cuda.device_count()\r\n","else:\r\n","    torch.cuda.set_device(args.local_rank)\r\n","    device = torch.device(\"cuda\", args.local_rank)\r\n","    n_gpu = 1\r\n","    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\r\n","    torch.distributed.init_process_group(backend='nccl')\r\n","\r\n","logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\r\n","    device, n_gpu, bool(args.local_rank != -1), args.fp16))\r\n","\r\n","if args.gradient_accumulation_steps < 1:\r\n","    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\r\n","                        args.gradient_accumulation_steps))\r\n","\r\n","args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\r\n","\r\n","random.seed(args.seed)\r\n","np.random.seed(args.seed)\r\n","torch.manual_seed(args.seed)\r\n","if n_gpu > 0:\r\n","    torch.cuda.manual_seed_all(args.seed)\r\n","\r\n","if not args.do_train and not args.do_eval:\r\n","    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\r\n","### kyoungman.bae @ 19-05-28\r\n","if args.openapi_key == None:\r\n","    raise ValueError(\"If you use the POS-based BPE, you must insert the access key.\")\r\n","\r\n","if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:\r\n","    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\r\n","if not os.path.exists(args.output_dir):\r\n","    os.makedirs(args.output_dir)\r\n","\r\n","task_name = args.task_name.lower()\r\n","\r\n","if task_name not in processors:\r\n","    raise ValueError(\"Task not found: %s\" % (task_name))\r\n","\r\n","processor = processors[task_name]()\r\n","### kyoungman.bae @ 19-05-28 \r\n","\r\n","label_list = ['0','1']\r\n","num_labels = len(label_list)\r\n","\r\n","### kyoungman.bae @ 19-05-28\r\n","tokenizer = mecab_tokenizer\r\n","\r\n","train_examples = None\r\n","num_train_optimization_steps = None\r\n","if args.do_train:\r\n","    train_examples = processor.get_train_examples(args.data_dir)\r\n","    num_train_optimization_steps = int(\r\n","        len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\r\n","    if args.local_rank != -1:\r\n","        num_train_optimization_steps = num_train_optimization_steps // torch.distributed.get_world_size()\r\n","\r\n","# Prepare model\r\n","cache_dir = args.cache_dir if args.cache_dir else os.path.join(str(PYTORCH_PRETRAINED_BERT_CACHE), 'distributed_{}'.format(args.local_rank))\r\n","model = BertForSequenceClassification.from_pretrained(args.bert_model_path,\r\n","          cache_dir=cache_dir,\r\n","          num_labels = num_labels)\r\n","if args.fp16:\r\n","    model.half()\r\n","model.to(device)\r\n","if args.local_rank != -1:\r\n","    try:\r\n","        from apex.parallel import DistributedDataParallel as DDP\r\n","    except ImportError:\r\n","        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\r\n","\r\n","    model = DDP(model)\r\n","elif n_gpu > 1:\r\n","    model = torch.nn.DataParallel(model)\r\n","\r\n","# Prepare optimizer\r\n","param_optimizer = list(model.named_parameters())\r\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\r\n","optimizer_grouped_parameters = [\r\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\r\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\r\n","    ]\r\n","if args.fp16:\r\n","    try:\r\n","        from apex.optimizers import FP16_Optimizer\r\n","        from apex.optimizers import FusedAdam\r\n","    except ImportError:\r\n","        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\r\n","\r\n","    optimizer = FusedAdam(optimizer_grouped_parameters,\r\n","                          lr=args.learning_rate,\r\n","                          bias_correction=False,\r\n","                          max_grad_norm=1.0)\r\n","    if args.loss_scale == 0:\r\n","        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\r\n","    else:\r\n","        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args.loss_scale)\r\n","\r\n","else:\r\n","    optimizer = BertAdam(optimizer_grouped_parameters,\r\n","                          lr=args.learning_rate,\r\n","                          warmup=args.warmup_proportion,\r\n","                          t_total=num_train_optimization_steps)\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bg19V3qwnAt1"},"source":["## 3.Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1db247c49f95441db1b3e594c478756e","4abbdb48d5d24d1d8a0dae536c0bc99d","b4ae90ec2ca7472c91c7e73a3cc6abb6","ea3c78d916554338bd2c8256dbf259ff","d895da7a68094a97a60ab7a0794b552a","aced469e66114b598fd0b1c37e8d2afa","4f625899dd93446f950d0d51776098df","c5ee7921ae3f46a19bbadb56d6d8cc1e","38fd78e4400a4d19866b6eeedd483472","27cfb43a3a0146d89c70099753f77cd4","0063cc413eb044c39837e7956e29e0a5","834ffdbc9d7d4379b06388856f9c48fc","8e2c6e5348714ba094b7d81dbb8a2898","6822b644ad434cb08ed47599f4d2a623","6a54cbad126b489ba3d4ed3300f5b15d","999b3fc97f2f4141b044584d75e08f91","afca0de462244a078ec0f417d1e074e5","6ec93ba8c16747fb9b1334f8456db039","c7a368dff88b415dad6659e34edb9cb3","afc5ee3957764053b141758432344465","8462ce9fd0494348afadeab3d0d60eef","564ce17861ba4ba0a12cbf8e1a706b8b","99cde03760bf4713b302afefd0461cb7","ba4f44e05c564376bdc23280693f4f29","a1a56753b4914d1680ffbcab279fcaec","09c2d8b8530c431680735bdd16597f3b","284d707154da4a0f9d5efe5a9d5c238f","1b32eda0b9304451aa03c07fbcf3c2a8","262f439c30624afe8b27ef153021a4c4","aa4e75cbb25f4a36b9082cc73fd78bfa","e738a153e7b240b4b0e1f706b11c5136","58b4492f8d2844d4bd9bd87a2e00bf22","e9afc37719004dd3977808227ac67796","3a56b362b2914a7fa71bc8af06286bff","36e03f0011c447bbb17c8672867b3181","8cf855fe8d3d4160974d8fc78b30ceaf","549e981b42d84d908107394dc79ba46c","2a2b4616f2814c11b330a4495c74c765","c5c845f804014a0c96ceacf150d61578","5d8d8f51231f448fbe751ac5599a5cfa","b9b6d4bcc3ab485082684f0177ea52e5","8df59fb361bd4b35b8fcecd2583c8956","66b4a3da6fe4457898d8d1afaf28c636","2f466af5e283483799718b33ace55c9f","760c5513feb6405695e613de585cb766","3a47f971d68f4b5bb175f3619c49d0bc","6401284de6ba482b8e54accc6cca86ff","52ccae12d1f046ada3da452fd15055c6","418623166f9f42869dc6af770dce1466","a4d23bcea341430894639f6a22cee552","a1eac4b6dc4943b39baa551081199673","6fe8e974554c436e804f18ee46960264","7f8373c8133b4749a1bea6bcf8d44a98","a7052ff4bd3a4fbabe442a2db576a181","d119cef17ab54b059b1947fb69d159da","90ce211d129b4588afdfc98277f4dbab","3057181306764341bd509ca7a0f2ade9","b008aff685f348f2b9ec696374781710","d609d75f19a648e98a7b54dde840fd68","5b9c1cb15cb9473c9caff03810f631fb","d255260ce4b845f08c3ad6648bbcec91","f67a737653fa4559b7541a0e8c6b8a9f","0e7ce60e97164f13b53646d3fad669bc","f7b388bc0c8245f1a01250399b60c375","46b8183833fd499db3d2555163a26300","8de4ea31ff5e4c518777b9d70436ccdb","757dae685c8844aea78bacaf0fa3c5d7","f4ed546053404a5f9058657664fde2fc","7647feb5eaa04c15ba3dacfa0ac2fb54","a19a8c8de46e492099c95d1c05b0de40","01c37a421eb741198191316aeecd7a03","7f4190ec47ed451b97c18bf29bb9dfe5","2aa1e66fb535426b9d3ce693212e6f3c","4a4c1895649849409dc94e589cf9b5b3","06204f18ce1845cba6b109d8595ffed6","701a90c5a4e1425cad9fb6cfe47058ba","192a1deb8934418b970bc84eaed02bfe","9ee544d1e82e4574b1b433cd898cba3e","59653ff68e874aa09504a85114669bdc","a5af0c413ddc42f1b8d029bf6733a828"]},"id":"3W5e_vn1Z_TA","executionInfo":{"status":"ok","timestamp":1609454869092,"user_tz":-540,"elapsed":11759387,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"5c939050-0b31-4fb7-a5d5-eb1ec397c6c9"},"source":["eval_examples = processor.get_dev_examples(args.data_dir)\r\n","eval_features = convert_examples_to_features(\r\n","    eval_examples, label_list, args.max_seq_length, tokenizer,args.openapi_key)\r\n","\r\n","all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\r\n","all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\r\n","all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\r\n","all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\r\n","eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\r\n","del all_input_ids, all_input_mask, all_segment_ids, all_label_ids\r\n","\r\n","# Run prediction for full data\r\n","eval_sampler = SequentialSampler(eval_data)\r\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\r\n","\r\n","\r\n","global_step = 0\r\n","nb_tr_steps = 0\r\n","tr_loss = 0\r\n","\r\n","if args.do_train:\r\n","    ### kyoungman.bae @ 19-05-30 @ do_anal_morp, openapi_accessKey 인수 추가\r\n","    train_features = convert_examples_to_features(\r\n","        train_examples, label_list, args.max_seq_length, tokenizer, args.openapi_key)                 \r\n","    if len(train_features) == 0:\r\n","        logger.info(\"The number of train_features is zero. Please check the tokenization. \")\r\n","        sys.exit()\r\n","\r\n","    logger.info(\"***** Running training *****\")\r\n","    logger.info(\"  Num examples = %d\", len(train_examples))\r\n","    logger.info(\"  Batch size = %d\", args.train_batch_size)\r\n","    logger.info(\"  Num steps = %d\", num_train_optimization_steps)\r\n","    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\r\n","    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\r\n","    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\r\n","    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\r\n","    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\r\n","    del all_input_ids, all_input_mask, all_segment_ids, all_label_ids\r\n","    if args.local_rank == -1:\r\n","        train_sampler = RandomSampler(train_data)\r\n","    else:\r\n","        train_sampler = DistributedSampler(train_data)\r\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\r\n","\r\n","    model.train()\r\n","    epoch=0\r\n","    for _ in trange(int(args.num_train_epochs), desc=\"Epoch\"):\r\n","#        train_logits = []\r\n","        \r\n","        epoch+=1\r\n","        tr_loss = 0\r\n","        nb_tr_examples, nb_tr_steps = 0, 0\r\n","        for step, batch in enumerate(notebook.tqdm(train_dataloader, desc=\"Iteration\")):\r\n","            batch = tuple(t.to(device) for t in batch)\r\n","            input_ids, input_mask, segment_ids, label_ids = batch\r\n","            loss = model(input_ids, segment_ids, input_mask, label_ids)\r\n","            logits = model(input_ids, segment_ids, input_mask)\r\n","\r\n","            #train_logits.append(logits)\r\n","\r\n","            logits = logits.detach().cpu().numpy()\r\n","            label_ids = label_ids.to('cpu').numpy()\r\n","\r\n","            if n_gpu > 1:\r\n","                loss = loss.mean() # mean() to average on multi-gpu.\r\n","            if args.gradient_accumulation_steps > 1:\r\n","                loss = loss / args.gradient_accumulation_steps\r\n","\r\n","            if args.fp16:\r\n","                optimizer.backward(loss)\r\n","            else:\r\n","                loss.backward()\r\n","\r\n","            tr_loss += loss.item()\r\n","            nb_tr_examples += input_ids.size(0)\r\n","            nb_tr_steps += 1\r\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\r\n","                if args.fp16:\r\n","                    # modify learning rate with special warm up BERT uses\r\n","                    # if args.fp16 is False, BertAdam is used that handles this automatically\r\n","                    lr_this_step = args.learning_rate * warmup_linear(global_step/num_train_optimization_steps, args.warmup_proportion)\r\n","                    for param_group in optimizer.param_groups:\r\n","                        param_group['lr'] = lr_this_step\r\n","                optimizer.step()\r\n","                optimizer.zero_grad()\r\n","                global_step += 1\r\n","\r\n","        model.eval()\r\n","        eval_loss, eval_accuracy = 0, 0\r\n","        nb_eval_steps, nb_eval_examples = 0, 0\r\n","        outputs = []\r\n","        ##################################################\r\n","        ### kyoungman.bae @ 19-05-31\r\n","        ### The classified result labels are displayed in the following path.\r\n","        output_eval_file = os.path.join(args.output_dir, \"eval_results_labels\"+str(epoch)+\".txt\")\r\n","        with open(output_eval_file, \"w\") as writer:\r\n","        \r\n","            for input_ids, input_mask, segment_ids, label_ids in notebook.tqdm(eval_dataloader, desc=\"Evaluating\"):\r\n","                input_ids = input_ids.to(device)\r\n","                input_mask = input_mask.to(device)\r\n","                segment_ids = segment_ids.to(device)\r\n","                label_ids = label_ids.to(device)\r\n","\r\n","                with torch.no_grad():\r\n","                    tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\r\n","                    logits = model(input_ids, segment_ids, input_mask)\r\n","                # val_logits.append(logits)\r\n","\r\n","                logits = logits.detach().cpu().numpy()\r\n","                label_ids = label_ids.to('cpu').numpy()\r\n","                ### kyoungman.bae @ 19-05-3\r\n","                current_out = np.argmax(logits, axis=1)\r\n","                for key in current_out:\r\n","                    writer.write(\"%s\\n\" % (int(key)))\r\n","\r\n","                tmp_eval_accuracy = accuracy(logits, label_ids)\r\n","\r\n","                eval_loss += tmp_eval_loss.mean().item()\r\n","                eval_accuracy += tmp_eval_accuracy\r\n","\r\n","                nb_eval_examples += input_ids.size(0)\r\n","                nb_eval_steps += 1\r\n","\r\n","        eval_loss = eval_loss / nb_eval_steps\r\n","        eval_accuracy = eval_accuracy / nb_eval_examples\r\n","        loss = tr_loss/nb_tr_steps if args.do_train else None\r\n","        result = {'eval_loss': eval_loss,\r\n","                  'eval_accuracy': eval_accuracy,\r\n","                  'global_step': global_step,\r\n","                  'loss': loss}\r\n","        \r\n","\r\n","        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\r\n","        with open(output_eval_file, \"w\") as writer:\r\n","            logger.info(\"***** Eval results *****\")\r\n","            for key in sorted(result.keys()):\r\n","                logger.info(\"  %s = %s\", key, str(result[key]))\r\n","                writer.write(\"%s = %s\\n\" % (key, str(result[key]))) \r\n","\r\n","\r\n","        print('Epoch = {}, loss = {}, val_loss = {}'.format(epoch, tr_loss/len(train_dataloader),eval_loss))\r\n","    # Save a trained model and the associated configuration\r\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\r\n","    output_model_file = os.path.join(args.output_dir, WEIGHTS_NAME)\r\n","    torch.save(model_to_save.state_dict(), output_model_file)\r\n","    output_config_file = os.path.join(args.output_dir, CONFIG_NAME)\r\n","    with open(output_config_file, 'w') as f:\r\n","        f.write(model_to_save.config.to_json_string())\r\n","\r\n","    # Load a trained model and config that you have fine-tuned\r\n","    config = BertConfig(output_config_file)\r\n","    model = BertForSequenceClassification(config, num_labels=num_labels)\r\n","    model.load_state_dict(torch.load(output_model_file))\r\n","else:\r\n","    model = BertForSequenceClassification.from_pretrained(args.bert_model_path, num_labels=num_labels)\r\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12/31/2020 19:31:53 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:53 - INFO - __main__ -   guid: dev-0\n","12/31/2020 19:31:53 - INFO - __main__ -   tokens: [CLS] 한국/NNP_ 기업/NNG_ 평가/NNG_ (/SS_ 034950/SN_ )/SS_ ,/SC_ 52/SN_ 주/NNB_ 신고/NNG_ 가/JKS_ [SEP] 2020/SN_ 年/NNG_ 상반기/NNG_ \"/SW_ 정부/NNG_ 정책/NNG_ \"/SW_ 최대/NNG_ 수/NNG_ 혜주/NNG_ TOP/SL_ 10/SN_ 긴급/NNG_ 공개/NNG_ ./SF_ ./SF_ [SEP]\n","12/31/2020 19:31:53 - INFO - __main__ -   input_ids: 2 98 381 481 27 1 28 1 3191 2225 1380 22 3 6070 1 1 1 176 640 1 721 158 1 1 111 3178 271 5 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   label: 1 (id = 1)\n","12/31/2020 19:31:53 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:53 - INFO - __main__ -   guid: dev-1\n","12/31/2020 19:31:53 - INFO - __main__ -   tokens: [CLS] 대림산업/NNP_ ,/SC_ 협/NNG_ 력사/NNG_ 상생/NNG_ 협력/NNG_ 기금/NNG_ 1000/SN_ 억/NR_ 원/NNB_ 규모/NNG_ 조성/NNG_ [SEP] 이/NP_ 는/JX_ 협력/NNG_ 회사/NNG_ 의/JKG_ 성장/NNG_ 이/JKS_ 곧/MAG_ 대림/NNP_ 의/JKG_ 경쟁력/NNG_ 강화/NNG_ 로/JKB_ 이어진다는/VV+ETM_ 철학/NNG_ 을/JKO_ 바탕/NNG_ 으로/JKB_ 하/VV_ 고/EC_ 있/VX_ 다/EC_ [SEP]\n","12/31/2020 19:31:53 - INFO - __main__ -   input_ids: 2 1 1 4241 1 1 1946 4185 2122 149 84 783 3047 3 75 16 1946 528 11 970 14 2675 1 11 1 1279 29 1 4051 9 2798 26 38 21 35 1515 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   label: 0 (id = 0)\n","12/31/2020 19:31:53 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:53 - INFO - __main__ -   guid: dev-2\n","12/31/2020 19:31:53 - INFO - __main__ -   tokens: [CLS] [/SS_ 속보/NNG_ ]/SS_ 코로나/NNP_ 19/SN_ 어제/NNG_ 13/SN_ 명/NNB_ 확진/NNG_ …/SE_ 국내/NNG_ 발생/NNG_ 6/SN_ ·/SC_ 해외/NNG_ 유입/NNG_ 7/SN_ 명/NNB_ [SEP] 아직/MAG_ 도/JX_ 추천/NNG_ 주/NNG_ 를/JKO_ 돈/NNG_ 내/VV_ 고/EC_ 받/VV_ 으세요/EF_ ./SF_ [SEP]\n","12/31/2020 19:31:53 - INFO - __main__ -   input_ids: 2 154 1 163 1 582 4932 523 85 1 180 407 549 106 1 1062 6029 123 85 3 667 32 3440 209 17 560 404 21 76 1 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   label: 1 (id = 1)\n","12/31/2020 19:31:53 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:53 - INFO - __main__ -   guid: dev-3\n","12/31/2020 19:31:53 - INFO - __main__ -   tokens: [CLS] [/SS_ 클릭/NNG_ e/SL_ 종목/NNG_ ]/SS_ 이/MM_ 커머스/NNG_ 는/JX_ 웃/VV_ 는데/EC_ …/SE_ 현대홈쇼핑/NNP_ ,/SC_ 2/SN_ 분기/NNG_ 도/JX_ 어렵/VA_ 다/EC_ [SEP] 다만/MAJ_ 송출/NNG_ 수수료/NNG_ 인하/NNG_ 에/JKB_ 따른/VV+ETM_ 효과/NNG_ 가/JKS_ 일정/NNG_ 부분/NNG_ 방어/NNG_ 할/XSV+ETM_ 수/NNB_ 있/VV_ 다는/ETM_ 분석/NNG_ 도/JX_ 있/VA_ 다/EC_ [SEP]\n","12/31/2020 19:31:53 - INFO - __main__ -   input_ids: 2 154 6216 993 2957 163 78 1 16 2057 135 180 1 1 52 1709 32 571 1515 3 1 1 1 3129 12 1 1161 22 1339 314 2801 1 53 1 87 740 32 36 1515 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   label: 0 (id = 0)\n","12/31/2020 19:31:53 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:53 - INFO - __main__ -   guid: dev-4\n","12/31/2020 19:31:53 - INFO - __main__ -   tokens: [CLS] 현대캐피탈/NNP_ ,/SC_ 車/NNG_ 자동/NNG_ 판독/NNG_ 시스템/NNG_ 구축/NNG_ [SEP] 오랜/MM_ 시간/NNG_ 의/JKG_ 학습/NNG_ 을/JKO_ 거친/VV+ETM_ 덕분/NNG_ 에/JKB_ 총/MM_ 470/SN_ 여/XSN_ 개/NNB_ 차종/NNG_ 을/JKO_ 97/SN_ %/SW_ 이상/NNG_ 의/JKG_ 정확도/NNG_ 로/JKB_ 인식/NNG_ 해/XSV+EC_ 낸다/VX+EC_ [SEP]\n","12/31/2020 19:31:53 - INFO - __main__ -   input_ids: 2 1 1 1 1044 1 1343 2896 3 3498 173 11 4776 9 1 3493 12 1172 1 422 152 8319 9 4303 79 235 11 1 29 1800 1 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:53 - INFO - __main__ -   label: 0 (id = 0)\n","12/31/2020 19:31:58 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:58 - INFO - __main__ -   guid: train-0\n","12/31/2020 19:31:58 - INFO - __main__ -   tokens: [CLS] 北/NNG_ ,/SC_ 미래/NNG_ 통합/NNG_ 당/XSN_ 창당/NNG_ 에/JKB_ “/SS_ 보수/NNG_ 되살린/VV+ETM_ 장본인/NNG_ 은/JX_ 남조선/NNP_ 당국/NNG_ ”/SS_ [SEP] 주식/NNG_ 시장/NNG_ 의/JKG_ 역사/NNG_ 를/JKO_ 다시/MAG_ 쓸/VV+ETM_ 역대/NNG_ 급/NNG_ 종목/NNG_ ./SW_ 목표/NNG_ 1700/SN_ %/SW_ 이상/NNG_ ./SF_ [SEP]\n","12/31/2020 19:31:58 - INFO - __main__ -   input_ids: 2 1 1 1756 1460 1320 6656 12 65 2252 1 1 19 1 1366 67 3 2117 261 11 1003 17 340 1 2454 569 2957 1 1532 10834 79 235 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   label: 1 (id = 1)\n","12/31/2020 19:31:58 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:58 - INFO - __main__ -   guid: train-1\n","12/31/2020 19:31:58 - INFO - __main__ -   tokens: [CLS] 동양/NNG_ ,/SC_ 임원/NNG_ ㆍ주요주주/UNKNOWN_ 특정/NNG_ 증권/NNG_ 등/NNB_ 소유주/NNG_ 식수/NNG_ 변동/NNG_ [SEP] 기간/NNG_ 무제한/NNG_ ./SW_ 이용료/NNG_ 0/SN_ 원/NNB_ ,/SC_ 주식/NNG_ 카톡/NNP_ 방/NNG_ 1/SN_ 천/NR_ 3/SN_ 백/NR_ 명/NNB_ ./SF_ 닫히/VV_ 기/ETN_ 직전/NNG_ ,/SC_ 지금/MAG_ 바로/MAG_ 입장/NNG_ ./SF_ ../SW_ [SEP]\n","12/31/2020 19:31:58 - INFO - __main__ -   input_ids: 2 7024 1 4373 1 2203 2593 49 1 1 4894 3 604 1 1 1 577 84 1 2117 1 544 48 318 61 3817 85 5 1 47 2979 1 1119 1034 542 5 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   label: 1 (id = 1)\n","12/31/2020 19:31:58 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:58 - INFO - __main__ -   guid: train-2\n","12/31/2020 19:31:58 - INFO - __main__ -   tokens: [CLS] 산림청/NNG_ ,/SC_ 산사태/NNG_ 취약/NNG_ 지역/NNG_ 실효/NNG_ 성/XSN_ 있/VV_ 는/ETM_ 제도/NNG_ 로/JKB_ 재/XPN_ 정비/NNG_ [SEP] 업계/NNG_ 최저/NNG_ 금리/NNG_ 2/SN_ ./SW_ 29/SN_ %./SW_ 100/SN_ %/SW_ 한/MM_ 종목/NNG_ 투자/NNG_ 가능/NNG_ +/SW_ 신용/NNG_ //SC_ 미수/NNG_ 대환/NNG_ 가능/NNG_ [SEP]\n","12/31/2020 19:31:58 - INFO - __main__ -   input_ids: 2 1 1 1 5480 257 8030 141 1 20 1270 29 648 3940 3 1146 2528 1675 52 1 831 1 556 79 90 2957 768 224 1307 2474 1 9679 1 224 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   label: 1 (id = 1)\n","12/31/2020 19:31:58 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:58 - INFO - __main__ -   guid: train-3\n","12/31/2020 19:31:58 - INFO - __main__ -   tokens: [CLS] [/SS_ 특징/NNG_ 주/NNG_ ]/SS_ 우리넷/NNP_ ,/SC_ 과기부/NNP_ 차세대/NNG_ 광통/NNG_ 신/XPN_ 시스템/NNG_ 주관/NNG_ 기관/NNG_ 선정/NNG_ ‘/SW_ 강세/NNG_ ’/SW_ [SEP] 이번/NNG_ 과제/NNG_ 는/JX_ 한국/NNP_ 전자/NNG_ 통신/NNG_ 연구원/NNG_ (/SS_ ETRI/SL_ )/SS_ ,/SC_ 코위버/NNP_ 등/NNB_ 국내/NNG_ 기업/NNG_ 과/JC_ 협업/NNG_ 을/JKO_ 통해/VV+EC_ 2022/SN_ 년/NNB_ 12/SN_ 월/NNB_ 까지/JX_ 개발/NNG_ 완료/NNG_ 를/JKO_ 목표/NNG_ 로/JKB_ 진행/NNG_ 된다/XSV+EC_ [SEP]\n","12/31/2020 19:31:58 - INFO - __main__ -   input_ids: 2 154 2645 209 163 1 1 1 1 1 1422 1343 5462 830 1548 1 7040 1 3 213 3648 16 98 1570 801 14161 27 1 28 1 1 49 407 381 44 1 9 1 1 37 234 58 77 565 4485 17 1532 29 356 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   label: 0 (id = 0)\n","12/31/2020 19:31:58 - INFO - __main__ -   *** Example ***\n","12/31/2020 19:31:58 - INFO - __main__ -   guid: train-4\n","12/31/2020 19:31:58 - INFO - __main__ -   tokens: [CLS] 카드/NNG_ 사/NR_ 앱/NNG_ 으로/JKB_ 결제/NNG_ 만/JX_ 하/VV_ 니/EF_ ?/SF_ …/SE_ 해외/NNG_ 주식/NNG_ ·/SC_ 펀드/NNG_ ·/SC_ 금/NNG_ 다/MAG_ 된다/VV+EC_ [SEP] 해외/NNG_ 주식/NNG_ 투자/NNG_ 의/JKG_ 경우/NNG_ 페이/NNP_ 북/NNP_ 전용/NNP_ 신한/NNP_ 금융/NNG_ 투자/NNG_ 계좌/NNG_ 를/JKO_ 개설/NNG_ 하/XSV_ 고/EC_ ,/SC_ 투자/NNG_ 금액/NNG_ 을/JKO_ 이체/NNG_ 한/XSV+ETM_ 후/NNG_ 해외/NNG_ 주식/NNG_ 을/JKO_ 선택/NNG_ 및/MAJ_ 수량/NNG_ 을/JKO_ 입력/NNG_ 하/XSV_ 면/EC_ 자동/NNG_ 으로/JKB_ 환전/NNG_ 과/JC_ 매매/NNG_ 가/JKS_ 완료/NNG_ 된다/XSV+EC_ [SEP]\n","12/31/2020 19:31:58 - INFO - __main__ -   input_ids: 2 886 9631 2547 26 3447 96 38 4318 143 180 1062 2117 1 3208 1 642 909 1 3 1062 2117 768 11 181 11503 2639 1 10328 754 768 4168 17 5699 7 21 1 768 2214 9 1 1 159 1062 2117 9 1055 322 1 9 6165 7 69 1044 26 1 44 2491 22 4485 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/31/2020 19:31:58 - INFO - __main__ -   label: 0 (id = 0)\n","12/31/2020 19:32:22 - INFO - __main__ -   ***** Running training *****\n","12/31/2020 19:32:22 - INFO - __main__ -     Num examples = 94996\n","12/31/2020 19:32:22 - INFO - __main__ -     Batch size = 16\n","12/31/2020 19:32:22 - INFO - __main__ -     Num steps = 29685\n","Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1db247c49f95441db1b3e594c478756e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5938.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38fd78e4400a4d19866b6eeedd483472","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1485.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["12/31/2020 20:11:56 - INFO - __main__ -   ***** Eval results *****\n","12/31/2020 20:11:56 - INFO - __main__ -     eval_accuracy = 0.9863152132721378\n","12/31/2020 20:11:56 - INFO - __main__ -     eval_loss = 0.04056818325316578\n","12/31/2020 20:11:56 - INFO - __main__ -     global_step = 5938\n","12/31/2020 20:11:56 - INFO - __main__ -     loss = 0.09008879510329292\n","Epoch:  20%|██        | 1/5 [39:33<2:38:12, 2373.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch = 1, loss = 0.09008879510329292, val_loss = 0.04056818325316578\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afca0de462244a078ec0f417d1e074e5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5938.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1a56753b4914d1680ffbcab279fcaec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1485.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["12/31/2020 20:50:54 - INFO - __main__ -   ***** Eval results *****\n","12/31/2020 20:50:54 - INFO - __main__ -     eval_accuracy = 0.9916206998189397\n","12/31/2020 20:50:54 - INFO - __main__ -     eval_loss = 0.03584455918841468\n","12/31/2020 20:50:54 - INFO - __main__ -     global_step = 11876\n","12/31/2020 20:50:54 - INFO - __main__ -     loss = 0.02049854192853788\n","Epoch:  40%|████      | 2/5 [1:18:31<1:58:07, 2362.66s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch = 2, loss = 0.02049854192853788, val_loss = 0.03584455918841468\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9afc37719004dd3977808227ac67796","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5938.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9b6d4bcc3ab485082684f0177ea52e5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1485.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["12/31/2020 21:29:52 - INFO - __main__ -   ***** Eval results *****\n","12/31/2020 21:29:52 - INFO - __main__ -     eval_accuracy = 0.9924628405406544\n","12/31/2020 21:29:52 - INFO - __main__ -     eval_loss = 0.03558957853989519\n","12/31/2020 21:29:52 - INFO - __main__ -     global_step = 17814\n","12/31/2020 21:29:52 - INFO - __main__ -     loss = 0.004595995947649947\n","Epoch:  60%|██████    | 3/5 [1:57:29<1:18:30, 2355.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch = 3, loss = 0.004595995947649947, val_loss = 0.03558957853989519\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"418623166f9f42869dc6af770dce1466","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5938.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3057181306764341bd509ca7a0f2ade9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1485.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["12/31/2020 22:08:48 - INFO - __main__ -   ***** Eval results *****\n","12/31/2020 22:08:48 - INFO - __main__ -     eval_accuracy = 0.9928418038654259\n","12/31/2020 22:08:48 - INFO - __main__ -     eval_loss = 0.03791232860711416\n","12/31/2020 22:08:48 - INFO - __main__ -     global_step = 23752\n","12/31/2020 22:08:48 - INFO - __main__ -     loss = 0.0013210052972689186\n","Epoch:  80%|████████  | 4/5 [2:36:24<39:09, 2349.36s/it]  "],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch = 4, loss = 0.0013210052972689186, val_loss = 0.03791232860711416\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46b8183833fd499db3d2555163a26300","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5938.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2aa1e66fb535426b9d3ce693212e6f3c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1485.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["12/31/2020 22:47:43 - INFO - __main__ -   ***** Eval results *****\n","12/31/2020 22:47:43 - INFO - __main__ -     eval_accuracy = 0.9934313023706262\n","12/31/2020 22:47:43 - INFO - __main__ -     eval_loss = 0.039735842211325915\n","12/31/2020 22:47:43 - INFO - __main__ -     global_step = 29690\n","12/31/2020 22:47:43 - INFO - __main__ -     loss = 0.00038581961663920706\n","Epoch: 100%|██████████| 5/5 [3:15:19<00:00, 2343.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch = 5, loss = 0.00038581961663920706, val_loss = 0.039735842211325915\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30349, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"7n2wIoXzneK8"},"source":["## 4. Inference"]},{"cell_type":"code","metadata":{"id":"lm8hiyd69bME"},"source":["%%time\r\n","test_examples = processor.get_test_examples(test_df)\r\n","test_features = convert_examples_to_features(\r\n","    test_examples, label_list, args.max_seq_length, tokenizer,vocab2id)\r\n","logger.info(\"***** Running evaluation *****\")\r\n","logger.info(\"  Num examples = %d\", len(test_examples))\r\n","logger.info(\"  Batch size = %d\", args.eval_batch_size)\r\n","all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\r\n","all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\r\n","all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\r\n","\r\n","eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\r\n","# Run prediction for full data\r\n","eval_sampler = SequentialSampler(eval_data)\r\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\r\n","\r\n","model.eval()\r\n","outputs = []\r\n","\r\n","for input_ids, input_mask, segment_ids, in notebook.tqdm(eval_dataloader, desc=\"Evaluating\"):\r\n","    input_ids = input_ids.to(device)\r\n","    input_mask = input_mask.to(device)\r\n","    segment_ids = segment_ids.to(device)\r\n","\r\n","\r\n","    with torch.no_grad():\r\n","        logits = model(input_ids, segment_ids, input_mask)\r\n","\r\n","    logits = logits.detach().cpu().numpy()\r\n","    current_out = np.argmax(logits, axis=1)\r\n","    outputs.extend(current_out)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vy_BLB6lFNr9"},"source":["Counter(outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"pFNtbE0KIlLz","executionInfo":{"status":"ok","timestamp":1609456751342,"user_tz":-540,"elapsed":13420319,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"22436271-8383-49c6-880b-4025444f24d5"},"source":["submission['info'] = outputs\r\n","submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>info</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NEWS00237_1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NEWS00237_2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NEWS00237_3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NEWS00237_4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NEWS00237_5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142560</th>\n","      <td>NEWS09482_72</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>142561</th>\n","      <td>NEWS09482_73</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>142562</th>\n","      <td>NEWS09482_74</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>142563</th>\n","      <td>NEWS09482_75</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>142564</th>\n","      <td>NEWS09482_76</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>142565 rows × 2 columns</p>\n","</div>"],"text/plain":["                  id  info\n","0        NEWS00237_1     0\n","1        NEWS00237_2     0\n","2        NEWS00237_3     0\n","3        NEWS00237_4     0\n","4        NEWS00237_5     0\n","...              ...   ...\n","142560  NEWS09482_72     1\n","142561  NEWS09482_73     1\n","142562  NEWS09482_74     1\n","142563  NEWS09482_75     1\n","142564  NEWS09482_76     1\n","\n","[142565 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["ef853bae0b4b4818b3e1b0aa82b5c878","5c0f77beb4104b36adeec6d73b526b0c","906762c963144135bc0a175344bc83a4","4b6fb492287f44bba756c9f8d08f7350","ce43ebfb28b14c48b090f73bc9859b39","26f2e1353f864427a19093ac986bfed9","5dc2fbe45a8b4025a373c75c7538f516","f54b600063f946379ff0caacac85e9a8"]},"id":"we-Pu15TJEwJ","executionInfo":{"status":"ok","timestamp":1609456785813,"user_tz":-540,"elapsed":34431,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"99e34e69-7caa-4949-a0b4-fc04f5c5195f"},"source":["train_unique_ad_sentence = train_df.query('info == \"1\"')['content'].unique()\r\n","test_content = test_df['content'].values\r\n","ad_index = []\r\n","for idx, sent in enumerate(notebook.tqdm(test_content)) : #Test 데이터에 있는 모든 content들에 대하여\r\n","\r\n","    if sent in train_unique_ad_sentence: # Train 데이터의 광고성 문구와 같은지 비교\r\n","        submission['info'].iloc[idx] = 1 # 같으면 1\r\n","        ad_index.append(idx)\r\n","    else : \r\n","        pass "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef853bae0b4b4818b3e1b0aa82b5c878","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=142565.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TNXQsmAJFSL","executionInfo":{"status":"ok","timestamp":1609331541116,"user_tz":-540,"elapsed":892,"user":{"displayName":"김태욱","photoUrl":"","userId":"14910750490911394154"}},"outputId":"92b7a821-6a71-4a08-ecee-e3a774d856a7"},"source":["submission['info'] = submission['info'].astype('int')\r\n","submission['info'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    89129\n","1    53436\n","Name: info, dtype: int64"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1yLB-2R1J_u2"},"source":["submission.to_csv('/content/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xlVdTIjDBS4"},"source":[""],"execution_count":null,"outputs":[]}]}